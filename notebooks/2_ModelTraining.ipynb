{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/keras/src/layers/core/dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 902us/step - accuracy: 0.9272 - loss: 0.2039 - val_accuracy: 0.9988 - val_loss: 0.0120\n",
      "Epoch 2/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - accuracy: 0.9985 - loss: 0.0155 - val_accuracy: 1.0000 - val_loss: 7.7932e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - accuracy: 0.9995 - loss: 0.0053 - val_accuracy: 1.0000 - val_loss: 2.3768e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540us/step - accuracy: 0.9997 - loss: 0.0022 - val_accuracy: 1.0000 - val_loss: 8.8475e-05\n",
      "Epoch 5/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - accuracy: 0.9997 - loss: 0.0027 - val_accuracy: 1.0000 - val_loss: 7.1950e-05\n",
      "Epoch 6/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 1.0000 - loss: 8.6087e-04 - val_accuracy: 1.0000 - val_loss: 4.2704e-05\n",
      "Epoch 7/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 0.9998 - loss: 7.0227e-04 - val_accuracy: 1.0000 - val_loss: 2.0852e-05\n",
      "Epoch 8/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 0.9997 - loss: 9.9764e-04 - val_accuracy: 1.0000 - val_loss: 7.1330e-06\n",
      "Epoch 9/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 1.0000 - loss: 3.6340e-04 - val_accuracy: 1.0000 - val_loss: 4.1846e-06\n",
      "Epoch 10/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 1.0000 - loss: 2.0371e-04 - val_accuracy: 1.0000 - val_loss: 2.7488e-06\n",
      "Epoch 11/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 1.0000 - loss: 1.7763e-04 - val_accuracy: 1.0000 - val_loss: 1.9520e-06\n",
      "Epoch 12/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 1.0000 - loss: 1.7040e-04 - val_accuracy: 1.0000 - val_loss: 1.4004e-06\n",
      "Epoch 13/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - accuracy: 1.0000 - loss: 2.4842e-04 - val_accuracy: 1.0000 - val_loss: 1.0293e-06\n",
      "Epoch 14/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 1.0000 - loss: 1.1587e-04 - val_accuracy: 1.0000 - val_loss: 1.1695e-06\n",
      "Epoch 15/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - accuracy: 1.0000 - loss: 1.0029e-04 - val_accuracy: 1.0000 - val_loss: 4.8364e-07\n",
      "Epoch 16/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - accuracy: 0.9997 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 2.7900e-06\n",
      "Epoch 17/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634us/step - accuracy: 0.9998 - loss: 2.8021e-04 - val_accuracy: 1.0000 - val_loss: 2.7448e-07\n",
      "Epoch 18/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - accuracy: 1.0000 - loss: 3.8648e-05 - val_accuracy: 1.0000 - val_loss: 2.1958e-07\n",
      "Epoch 19/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - accuracy: 1.0000 - loss: 5.7085e-05 - val_accuracy: 1.0000 - val_loss: 1.7310e-07\n",
      "Epoch 20/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 1.0000 - loss: 3.6165e-05 - val_accuracy: 1.0000 - val_loss: 1.3691e-07\n",
      "Epoch 21/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - accuracy: 1.0000 - loss: 3.7392e-05 - val_accuracy: 1.0000 - val_loss: 1.1290e-07\n",
      "Epoch 22/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - accuracy: 1.0000 - loss: 2.9348e-05 - val_accuracy: 1.0000 - val_loss: 8.7877e-08\n",
      "Epoch 23/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - accuracy: 1.0000 - loss: 1.7794e-05 - val_accuracy: 1.0000 - val_loss: 7.3077e-08\n",
      "Epoch 24/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 1.0000 - loss: 5.5629e-05 - val_accuracy: 1.0000 - val_loss: 4.9258e-08\n",
      "Epoch 25/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 1.0000 - loss: 2.3318e-05 - val_accuracy: 1.0000 - val_loss: 3.9780e-08\n",
      "Epoch 26/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - accuracy: 1.0000 - loss: 3.5549e-05 - val_accuracy: 1.0000 - val_loss: 2.6480e-08\n",
      "Epoch 27/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537us/step - accuracy: 0.9998 - loss: 6.0646e-04 - val_accuracy: 1.0000 - val_loss: 3.0946e-08\n",
      "Epoch 28/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - accuracy: 1.0000 - loss: 2.3559e-05 - val_accuracy: 1.0000 - val_loss: 2.2933e-08\n",
      "Epoch 29/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 1.0000 - loss: 4.8999e-05 - val_accuracy: 1.0000 - val_loss: 1.4055e-08\n",
      "Epoch 30/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step - accuracy: 1.0000 - loss: 1.7986e-05 - val_accuracy: 1.0000 - val_loss: 1.0811e-08\n",
      "Epoch 31/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - accuracy: 1.0000 - loss: 1.4634e-05 - val_accuracy: 1.0000 - val_loss: 8.8636e-09\n",
      "Epoch 32/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - accuracy: 1.0000 - loss: 5.6244e-06 - val_accuracy: 1.0000 - val_loss: 7.7761e-09\n",
      "Epoch 33/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - accuracy: 1.0000 - loss: 2.1678e-05 - val_accuracy: 1.0000 - val_loss: 5.8094e-09\n",
      "Epoch 34/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 1.0000 - loss: 3.7895e-05 - val_accuracy: 1.0000 - val_loss: 6.3462e-09\n",
      "Epoch 35/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - accuracy: 1.0000 - loss: 7.4435e-06 - val_accuracy: 1.0000 - val_loss: 4.7370e-09\n",
      "Epoch 36/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 1.0000 - loss: 1.4912e-05 - val_accuracy: 1.0000 - val_loss: 3.0538e-09\n",
      "Epoch 37/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - accuracy: 1.0000 - loss: 1.5003e-05 - val_accuracy: 1.0000 - val_loss: 2.6234e-09\n",
      "Epoch 38/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - accuracy: 1.0000 - loss: 5.3108e-06 - val_accuracy: 1.0000 - val_loss: 1.8230e-09\n",
      "Epoch 39/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - accuracy: 1.0000 - loss: 3.9112e-06 - val_accuracy: 1.0000 - val_loss: 1.4396e-09\n",
      "Epoch 40/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 551us/step - accuracy: 1.0000 - loss: 7.2963e-06 - val_accuracy: 1.0000 - val_loss: 1.0591e-09\n",
      "Epoch 41/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512us/step - accuracy: 1.0000 - loss: 3.1838e-05 - val_accuracy: 1.0000 - val_loss: 1.0272e-09\n",
      "Epoch 42/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - accuracy: 1.0000 - loss: 3.1910e-06 - val_accuracy: 1.0000 - val_loss: 8.1973e-10\n",
      "Epoch 43/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - accuracy: 1.0000 - loss: 2.9658e-06 - val_accuracy: 1.0000 - val_loss: 6.4465e-10\n",
      "Epoch 44/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 1.0000 - loss: 6.3906e-06 - val_accuracy: 1.0000 - val_loss: 4.8075e-10\n",
      "Epoch 45/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - accuracy: 1.0000 - loss: 1.5503e-06 - val_accuracy: 1.0000 - val_loss: 3.6238e-10\n",
      "Epoch 46/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - accuracy: 1.0000 - loss: 2.4844e-06 - val_accuracy: 1.0000 - val_loss: 2.7535e-10\n",
      "Epoch 47/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 1.0000 - loss: 8.0488e-07 - val_accuracy: 1.0000 - val_loss: 2.4210e-10\n",
      "Epoch 48/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - accuracy: 1.0000 - loss: 1.3119e-06 - val_accuracy: 1.0000 - val_loss: 2.0199e-10\n",
      "Epoch 49/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540us/step - accuracy: 1.0000 - loss: 1.8897e-05 - val_accuracy: 1.0000 - val_loss: 1.0269e-10\n",
      "Epoch 50/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - accuracy: 1.0000 - loss: 8.2011e-06 - val_accuracy: 1.0000 - val_loss: 4.2967e-11\n",
      "Epoch 51/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 1.0000 - loss: 2.6640e-06 - val_accuracy: 1.0000 - val_loss: 3.4975e-11\n",
      "Epoch 52/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 1.0000 - loss: 5.2274e-07 - val_accuracy: 1.0000 - val_loss: 3.1797e-11\n",
      "Epoch 53/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - accuracy: 1.0000 - loss: 1.1616e-06 - val_accuracy: 1.0000 - val_loss: 2.4140e-11\n",
      "Epoch 54/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - accuracy: 1.0000 - loss: 4.0186e-06 - val_accuracy: 1.0000 - val_loss: 1.8519e-11\n",
      "Epoch 55/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541us/step - accuracy: 1.0000 - loss: 6.5245e-06 - val_accuracy: 1.0000 - val_loss: 1.7210e-11\n",
      "Epoch 56/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step - accuracy: 1.0000 - loss: 3.8976e-07 - val_accuracy: 1.0000 - val_loss: 1.5041e-11\n",
      "Epoch 57/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554us/step - accuracy: 1.0000 - loss: 2.7718e-05 - val_accuracy: 1.0000 - val_loss: 1.4064e-11\n",
      "Epoch 58/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537us/step - accuracy: 1.0000 - loss: 1.6153e-06 - val_accuracy: 1.0000 - val_loss: 9.0822e-12\n",
      "Epoch 59/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 546us/step - accuracy: 1.0000 - loss: 2.3098e-06 - val_accuracy: 1.0000 - val_loss: 4.3790e-12\n",
      "Epoch 60/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 552us/step - accuracy: 1.0000 - loss: 1.7522e-06 - val_accuracy: 1.0000 - val_loss: 3.8757e-12\n",
      "Epoch 61/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - accuracy: 1.0000 - loss: 4.3642e-07 - val_accuracy: 1.0000 - val_loss: 2.6085e-12\n",
      "Epoch 62/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 552us/step - accuracy: 1.0000 - loss: 8.6854e-07 - val_accuracy: 1.0000 - val_loss: 2.1807e-12\n",
      "Epoch 63/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 552us/step - accuracy: 1.0000 - loss: 1.4372e-06 - val_accuracy: 1.0000 - val_loss: 2.0186e-12\n",
      "Epoch 64/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536us/step - accuracy: 1.0000 - loss: 5.4592e-07 - val_accuracy: 1.0000 - val_loss: 1.1869e-12\n",
      "Epoch 65/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538us/step - accuracy: 1.0000 - loss: 1.4302e-07 - val_accuracy: 1.0000 - val_loss: 9.7966e-13\n",
      "Epoch 66/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548us/step - accuracy: 1.0000 - loss: 4.8956e-07 - val_accuracy: 1.0000 - val_loss: 6.6268e-13\n",
      "Epoch 67/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553us/step - accuracy: 1.0000 - loss: 4.4003e-07 - val_accuracy: 1.0000 - val_loss: 3.8759e-13\n",
      "Epoch 68/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540us/step - accuracy: 1.0000 - loss: 2.1310e-07 - val_accuracy: 1.0000 - val_loss: 3.1417e-13\n",
      "Epoch 69/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - accuracy: 1.0000 - loss: 1.5095e-07 - val_accuracy: 1.0000 - val_loss: 2.6857e-13\n",
      "Epoch 70/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - accuracy: 1.0000 - loss: 6.7103e-08 - val_accuracy: 1.0000 - val_loss: 2.4430e-13\n",
      "Epoch 71/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565us/step - accuracy: 1.0000 - loss: 2.3386e-06 - val_accuracy: 1.0000 - val_loss: 2.5492e-13\n",
      "Epoch 72/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565us/step - accuracy: 1.0000 - loss: 1.1541e-07 - val_accuracy: 1.0000 - val_loss: 2.4040e-13\n",
      "Epoch 73/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - accuracy: 1.0000 - loss: 9.5715e-08 - val_accuracy: 1.0000 - val_loss: 2.1859e-13\n",
      "Epoch 74/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566us/step - accuracy: 1.0000 - loss: 1.4053e-07 - val_accuracy: 1.0000 - val_loss: 1.7666e-13\n",
      "Epoch 75/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - accuracy: 1.0000 - loss: 2.6211e-07 - val_accuracy: 1.0000 - val_loss: 1.3093e-13\n",
      "Epoch 76/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561us/step - accuracy: 1.0000 - loss: 1.1149e-06 - val_accuracy: 1.0000 - val_loss: 1.2046e-13\n",
      "Epoch 77/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step - accuracy: 1.0000 - loss: 1.5767e-07 - val_accuracy: 1.0000 - val_loss: 9.6066e-14\n",
      "Epoch 78/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - accuracy: 1.0000 - loss: 3.6619e-07 - val_accuracy: 1.0000 - val_loss: 8.2948e-14\n",
      "Epoch 79/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 549us/step - accuracy: 1.0000 - loss: 6.4509e-08 - val_accuracy: 1.0000 - val_loss: 5.9469e-14\n",
      "Epoch 80/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 552us/step - accuracy: 1.0000 - loss: 3.0014e-07 - val_accuracy: 1.0000 - val_loss: 5.2179e-14\n",
      "Epoch 81/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542us/step - accuracy: 1.0000 - loss: 6.2012e-07 - val_accuracy: 1.0000 - val_loss: 4.5293e-14\n",
      "Epoch 82/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544us/step - accuracy: 1.0000 - loss: 4.8587e-08 - val_accuracy: 1.0000 - val_loss: 4.2341e-14\n",
      "Epoch 83/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544us/step - accuracy: 1.0000 - loss: 1.6393e-07 - val_accuracy: 1.0000 - val_loss: 1.4849e-14\n",
      "Epoch 84/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - accuracy: 1.0000 - loss: 9.5696e-08 - val_accuracy: 1.0000 - val_loss: 7.8441e-15\n",
      "Epoch 85/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 547us/step - accuracy: 1.0000 - loss: 1.2417e-08 - val_accuracy: 1.0000 - val_loss: 6.8324e-15\n",
      "Epoch 86/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537us/step - accuracy: 1.0000 - loss: 4.6449e-09 - val_accuracy: 1.0000 - val_loss: 6.3178e-15\n",
      "Epoch 87/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544us/step - accuracy: 1.0000 - loss: 5.3775e-08 - val_accuracy: 1.0000 - val_loss: 4.5278e-15\n",
      "Epoch 88/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540us/step - accuracy: 1.0000 - loss: 2.4284e-08 - val_accuracy: 1.0000 - val_loss: 4.0811e-15\n",
      "Epoch 89/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538us/step - accuracy: 1.0000 - loss: 1.5734e-08 - val_accuracy: 1.0000 - val_loss: 3.2600e-15\n",
      "Epoch 90/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 550us/step - accuracy: 1.0000 - loss: 5.4766e-09 - val_accuracy: 1.0000 - val_loss: 2.9638e-15\n",
      "Epoch 91/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543us/step - accuracy: 1.0000 - loss: 5.7492e-08 - val_accuracy: 1.0000 - val_loss: 7.6336e-16\n",
      "Epoch 92/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - accuracy: 1.0000 - loss: 1.8614e-08 - val_accuracy: 1.0000 - val_loss: 5.9938e-16\n",
      "Epoch 93/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540us/step - accuracy: 1.0000 - loss: 1.2678e-08 - val_accuracy: 1.0000 - val_loss: 4.5973e-16\n",
      "Epoch 94/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 552us/step - accuracy: 1.0000 - loss: 3.3984e-09 - val_accuracy: 1.0000 - val_loss: 4.4614e-16\n",
      "Epoch 95/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 547us/step - accuracy: 1.0000 - loss: 3.4575e-08 - val_accuracy: 1.0000 - val_loss: 2.7042e-16\n",
      "Epoch 96/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 552us/step - accuracy: 1.0000 - loss: 1.6105e-06 - val_accuracy: 1.0000 - val_loss: 1.8077e-16\n",
      "Epoch 97/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561us/step - accuracy: 1.0000 - loss: 1.3032e-08 - val_accuracy: 1.0000 - val_loss: 1.6827e-16\n",
      "Epoch 98/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 550us/step - accuracy: 1.0000 - loss: 2.0699e-07 - val_accuracy: 1.0000 - val_loss: 3.9564e-17\n",
      "Epoch 99/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555us/step - accuracy: 1.0000 - loss: 1.4089e-08 - val_accuracy: 1.0000 - val_loss: 3.0948e-17\n",
      "Epoch 100/100\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542us/step - accuracy: 1.0000 - loss: 6.4912e-09 - val_accuracy: 1.0000 - val_loss: 2.4761e-17\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468us/step\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1699    0]\n",
      " [   0  327]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1699\n",
      "           1       1.00      1.00      1.00       327\n",
      "\n",
      "    accuracy                           1.00      2026\n",
      "   macro avg       1.00      1.00      1.00      2026\n",
      "weighted avg       1.00      1.00      1.00      2026\n",
      "\n",
      "ROC AUC Score: 1.0\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213us/step\n",
      "\n",
      "Churn probabilities saved to '../data/churn_probabilities.csv'\n"
     ]
    }
   ],
   "source": [
    "# 2_ModelTraining.ipynb\n",
    "\n",
    "# --------------------------------------------\n",
    "# 1. IMPORT LIBRARIES\n",
    "# --------------------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import joblib  # for saving/loading scaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "# Suppress protobuf warnings from TensorFlow\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='google.protobuf')\n",
    "\n",
    "# --------------------------------------------\n",
    "# 2. LOAD DATA FROM PREVIOUS NOTEBOOK\n",
    "# --------------------------------------------\n",
    "\n",
    "X_train = np.load('../data/X_train.npy')\n",
    "X_test = np.load('../data/X_test.npy')\n",
    "y_train = np.load('../data/y_train.npy')\n",
    "y_test = np.load('../data/y_test.npy')\n",
    "\n",
    "# Load the scaler used during training\n",
    "scaler = joblib.load('../models/scaler.save')\n",
    "\n",
    "# --------------------------------------------\n",
    "# 3. BUILD MODEL (Keras ANN)\n",
    "# --------------------------------------------\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')  # Binary classification output\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# --------------------------------------------\n",
    "# 4. TRAIN MODEL\n",
    "# --------------------------------------------\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# --------------------------------------------\n",
    "# 5. EVALUATE MODEL\n",
    "# --------------------------------------------\n",
    "\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_test, y_pred_prob))\n",
    "\n",
    "# --------------------------------------------\n",
    "# 6. SAVE MODEL\n",
    "# --------------------------------------------\n",
    "\n",
    "model.save('../models/churn_model.h5')\n",
    "\n",
    "# --------------------------------------------\n",
    "# 7. EXPORT PREDICTIONS (Optional)\n",
    "# --------------------------------------------\n",
    "\n",
    "# Load original dataset\n",
    "df = pd.read_csv('../data/BankChurners.csv')\n",
    "\n",
    "# Drop columns (ignore errors if missing)\n",
    "drop_cols = [\n",
    "    'CLIENTNUM',\n",
    "    'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon',\n",
    "    'Naive_Bayes_Classifier_Attrition_Flag_Income_Category_Age'\n",
    "]\n",
    "df.drop(columns=drop_cols, inplace=True, errors='ignore')\n",
    "\n",
    "# Create target column and drop original\n",
    "df['Churn'] = df['Attrition_Flag'].apply(lambda x: 1 if x == 'Attrited Customer' else 0)\n",
    "df.drop('Attrition_Flag', axis=1, inplace=True)\n",
    "\n",
    "# One-hot encode with the same columns as training:\n",
    "df_encoded = pd.get_dummies(df, drop_first=True)\n",
    "\n",
    "# Make sure columns in df_encoded match training features exactly\n",
    "# Load training feature columns list\n",
    "train_features = joblib.load('../models/train_features.save')\n",
    "\n",
    "# Reindex to training columns, fill missing cols with 0\n",
    "df_encoded = df_encoded.reindex(columns=train_features, fill_value=0)\n",
    "\n",
    "# Scale features with loaded scaler\n",
    "X_full_scaled = scaler.transform(df_encoded)\n",
    "\n",
    "# Predict churn probabilities\n",
    "probs_full = model.predict(X_full_scaled)\n",
    "\n",
    "df['Churn_Prob'] = probs_full\n",
    "\n",
    "# Save churn probabilities to CSV\n",
    "df[['Churn_Prob']].to_csv('../data/churn_probabilities.csv', index=False)\n",
    "\n",
    "print(\"\\nChurn probabilities saved to '../data/churn_probabilities.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
